{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from nltk.corpus import stopwords\n",
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf = SparkConf().set(\"spark.jars\", \"./spark-nlp_2.11-2.4.5.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.2.13:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a211ea190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparknlp.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .option(\"parserLib\", \"univocity\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .csv(\"tweets\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1238253442063310848</td>\n",
       "      <td>532343475</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>The UFC is about to be the most popular sport ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1238253441778098177</td>\n",
       "      <td>165879150</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>The great toilet paper depression of 2020 #Toi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1238253440486313988</td>\n",
       "      <td>569242704</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>The 'Spotlight Show' with @janeyleegrace on @u...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1238253439051870208</td>\n",
       "      <td>16368021</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>Because we all the time in the world right? @s...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1238253440821649408</td>\n",
       "      <td>1057148786189824000</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>French pastry chef shows off Easter eggs model...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1238253442034020354</td>\n",
       "      <td>1093544067219292161</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>ICYMI - Hour 2 of #TheGamePlan with @DaveWNSP ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1238253441564266496</td>\n",
       "      <td>39743812</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>With rising #Coronavirus cases in India, which...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1238253441517928448</td>\n",
       "      <td>17852186</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>#ICYMI: #Ontario #MPPs may temporarily suspend...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1238253440603541504</td>\n",
       "      <td>1454687180</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>Despite having only 3 confirmed #coronavirus c...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1238253440461135873</td>\n",
       "      <td>19047089</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>Autonomous #Robots Are Helping Kill #Coronavir...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id              user_id            created_at  \\\n",
       "0  1238253442063310848            532343475  2020-03-13T00:00:00Z   \n",
       "1  1238253441778098177            165879150  2020-03-13T00:00:00Z   \n",
       "2  1238253440486313988            569242704  2020-03-13T00:00:00Z   \n",
       "3  1238253439051870208             16368021  2020-03-13T00:00:00Z   \n",
       "4  1238253440821649408  1057148786189824000  2020-03-13T00:00:00Z   \n",
       "5  1238253442034020354  1093544067219292161  2020-03-13T00:00:00Z   \n",
       "6  1238253441564266496             39743812  2020-03-13T00:00:00Z   \n",
       "7  1238253441517928448             17852186  2020-03-13T00:00:00Z   \n",
       "8  1238253440603541504           1454687180  2020-03-13T00:00:00Z   \n",
       "9  1238253440461135873             19047089  2020-03-13T00:00:00Z   \n",
       "\n",
       "                                                text lang  \n",
       "0  The UFC is about to be the most popular sport ...   en  \n",
       "1  The great toilet paper depression of 2020 #Toi...   en  \n",
       "2  The 'Spotlight Show' with @janeyleegrace on @u...   en  \n",
       "3  Because we all the time in the world right? @s...   en  \n",
       "4  French pastry chef shows off Easter eggs model...   en  \n",
       "5  ICYMI - Hour 2 of #TheGamePlan with @DaveWNSP ...   en  \n",
       "6  With rising #Coronavirus cases in India, which...   en  \n",
       "7  #ICYMI: #Ontario #MPPs may temporarily suspend...   en  \n",
       "8  Despite having only 3 confirmed #coronavirus c...   en  \n",
       "9  Autonomous #Robots Are Helping Kill #Coronavir...   en  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "# sentence_detector = SentenceDetector() \\\n",
    "#     .setInputCols([\"document\"]) \\\n",
    "#     .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normal\")\\\n",
    "    .setCleanupPatterns(['[^A-Za-z]', 'http.*'])\\\n",
    "    .setLowercase(True)\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"normal\"]) \\\n",
    "    .setOutputCol(\"clean\") \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setStopWords(eng_stopwords)\n",
    "\n",
    "# lemmatizer = LemmatizerModel.pretrained() \\\n",
    "#     .setInputCols([\"clean\"]) \\\n",
    "#     .setOutputCol(\"lemma\")\n",
    "\n",
    "lemmatizer=LemmatizerModel.load('lemma_antbnc_en_2.0.2_2.4_1556480454569/')\\\n",
    "    .setInputCols([\"clean\"]) \\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "    .setInputCols([\"lemma\"]) \\\n",
    "    .setOutputCol(\"stem\")\n",
    "\n",
    "# word_embeddings=ElmoEmbeddings.pretrained()\\\n",
    "#     .setInputCols([\"document\", \"lemma\"])\\\n",
    "#     .setOutputCol(\"embedding\")\n",
    "\n",
    "# word_embeddings=ElmoEmbeddings.load('elmo_en_2.4.0_2.4_1580488815299/')\\\n",
    "#     .setInputCols([\"document\", \"lemma\"])\\\n",
    "#     .setOutputCol(\"embedding\")\n",
    "\n",
    "\n",
    "# sentence_embeddings=SentenceEmbeddings()\\\n",
    "#     .setInputCols([\"document\", \"embedding\"])\\\n",
    "#     .setOutputCol(\"sentence_embedding\")\\\n",
    "#     .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "\n",
    "ngrams_cum = NGramGenerator() \\\n",
    "    .setInputCols([\"stem\"]) \\\n",
    "    .setOutputCol(\"ngram\") \\\n",
    "    .setN(2) \\\n",
    "    .setEnableCumulative(True)\\\n",
    "    .setDelimiter(\"_\") # Default is space\n",
    "\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"ngram\"]) \\\n",
    "    .setOutputCols(['tokens'])\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "#     sentence_detector, \n",
    "    tokenizer, \n",
    "    normalizer, \n",
    "    stopwords_cleaner,\n",
    "    lemmatizer,\n",
    "    stemmer,\n",
    "#     word_embeddings,\n",
    "#     sentence_embeddings,\n",
    "    ngrams_cum,\n",
    "    finisher\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.select(\n",
    "        'status_id',\n",
    "        'created_at',\n",
    "        F.from_unixtime(F.unix_timestamp('created_at', 'yyyy-MM-dd')).cast('timestamp').alias('date'),\n",
    "        F.explode(\"tokens\").alias(\"word\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.groupBy(['word', 'date'])\\\n",
    "    .agg(F.countDistinct(\"status_id\").alias(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>date</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ufc</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>popular</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sport</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>entir</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>world</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6636</td>\n",
       "      <td>univers_amp</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6637</td>\n",
       "      <td>self</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6638</td>\n",
       "      <td>perhap</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6639</td>\n",
       "      <td>face_disciplin</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6640</td>\n",
       "      <td>bulk_order</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6641 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word       date  count\n",
       "0                ufc 2020-03-13      1\n",
       "1            popular 2020-03-13      1\n",
       "2              sport 2020-03-13     15\n",
       "3              entir 2020-03-13      1\n",
       "4              world 2020-03-13     17\n",
       "...              ...        ...    ...\n",
       "6636     univers_amp 2020-03-13      1\n",
       "6637            self 2020-03-13      2\n",
       "6638          perhap 2020-03-13      1\n",
       "6639  face_disciplin 2020-03-13      1\n",
       "6640      bulk_order 2020-03-13      1\n",
       "\n",
       "[6641 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result.toPandas()\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .option(\"parserLib\", \"univocity\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(\"word_count.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spark.read\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .option(\"parserLib\", \"univocity\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .parquet(\"word_count.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result.groupby('word')\\\n",
    "    .agg(F.sum('count').alias('count'))\\\n",
    "    .orderBy(F.desc('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [row[0] for row in result2.limit(1000).select('word').collect()]\n",
    "if 'date' in words:\n",
    "    words.remove('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = result.groupBy('date').pivot('word', words).max('count').orderBy('date').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>coronaviru</th>\n",
       "      <th>covid</th>\n",
       "      <th>coronaviruspandem</th>\n",
       "      <th>peopl</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>ne</th>\n",
       "      <th>time</th>\n",
       "      <th>spread</th>\n",
       "      <th>...</th>\n",
       "      <th>french</th>\n",
       "      <th>egg</th>\n",
       "      <th>pastri_chef</th>\n",
       "      <th>easteregg_coronaviru</th>\n",
       "      <th>ncaatourna</th>\n",
       "      <th>hour_thegameplan</th>\n",
       "      <th>nfl_ncaa</th>\n",
       "      <th>railwai</th>\n",
       "      <th>rise_coronaviru</th>\n",
       "      <th>effort_bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>239</td>\n",
       "      <td>143</td>\n",
       "      <td>77</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  coronaviru  covid  coronaviruspandem  peopl  get  go  ne  time  \\\n",
       "0 2020-03-13         239    143                 77     32   29  27  24    24   \n",
       "\n",
       "   spread  ...  french  egg  pastri_chef  easteregg_coronaviru  ncaatourna  \\\n",
       "0      23  ...       1    1            1                     1           1   \n",
       "\n",
       "   hour_thegameplan  nfl_ncaa  railwai  rise_coronaviru  effort_bid  \n",
       "0                 1         1        1                1           1  \n",
       "\n",
       "[1 rows x 1001 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases = spark.read.csv('covid19.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases = df_cases.filter(F.col('prname') == 'Canada')\\\n",
    "    .select(\n",
    "        F.from_unixtime(F.unix_timestamp('date', 'dd-MM-yyyy')).cast('timestamp').alias('date'),\n",
    "        F.col('numconf').cast('Long'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = result3.join(df_cases, on='date', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4.stat.corr(\"coronaviru\", \"numconf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(coronaviru=239)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4.select(\"coronaviru\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coefs = [result4.stat.corr(w, 'numconf') for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
