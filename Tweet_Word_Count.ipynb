{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Window, Row\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from nltk.corpus import stopwords\n",
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf = SparkConf().set(\"spark.jars\", \"./spark-nlp_2.11-2.4.5.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.2.13:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a211ea190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparknlp.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .option(\"parserLib\", \"univocity\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .csv(\"tweets\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1238253442063310848</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>The UFC is about to be the most popular sport ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1238253441778098177</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>The great toilet paper depression of 2020 #Toi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1238253440486313988</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>The 'Spotlight Show' with @janeyleegrace on @u...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1238253439051870208</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>Because we all the time in the world right? @s...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1238253440821649408</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>French pastry chef shows off Easter eggs model...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1238253442034020354</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>ICYMI - Hour 2 of #TheGamePlan with @DaveWNSP ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1238253441564266496</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>With rising #Coronavirus cases in India, which...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1238253441517928448</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>#ICYMI: #Ontario #MPPs may temporarily suspend...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1238253440603541504</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>Despite having only 3 confirmed #coronavirus c...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1238253440461135873</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>Autonomous #Robots Are Helping Kill #Coronavir...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id            created_at  \\\n",
       "0  1238253442063310848  2020-03-13T00:00:00Z   \n",
       "1  1238253441778098177  2020-03-13T00:00:00Z   \n",
       "2  1238253440486313988  2020-03-13T00:00:00Z   \n",
       "3  1238253439051870208  2020-03-13T00:00:00Z   \n",
       "4  1238253440821649408  2020-03-13T00:00:00Z   \n",
       "5  1238253442034020354  2020-03-13T00:00:00Z   \n",
       "6  1238253441564266496  2020-03-13T00:00:00Z   \n",
       "7  1238253441517928448  2020-03-13T00:00:00Z   \n",
       "8  1238253440603541504  2020-03-13T00:00:00Z   \n",
       "9  1238253440461135873  2020-03-13T00:00:00Z   \n",
       "\n",
       "                                                text lang  \n",
       "0  The UFC is about to be the most popular sport ...   en  \n",
       "1  The great toilet paper depression of 2020 #Toi...   en  \n",
       "2  The 'Spotlight Show' with @janeyleegrace on @u...   en  \n",
       "3  Because we all the time in the world right? @s...   en  \n",
       "4  French pastry chef shows off Easter eggs model...   en  \n",
       "5  ICYMI - Hour 2 of #TheGamePlan with @DaveWNSP ...   en  \n",
       "6  With rising #Coronavirus cases in India, which...   en  \n",
       "7  #ICYMI: #Ontario #MPPs may temporarily suspend...   en  \n",
       "8  Despite having only 3 confirmed #coronavirus c...   en  \n",
       "9  Autonomous #Robots Are Helping Kill #Coronavir...   en  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(10).toPandas().drop(columns='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "# sentence_detector = SentenceDetector() \\\n",
    "#     .setInputCols([\"document\"]) \\\n",
    "#     .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normal\")\\\n",
    "    .setCleanupPatterns(['[^A-Za-z]', 'http.*'])\\\n",
    "    .setLowercase(True)\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"normal\"]) \\\n",
    "    .setOutputCol(\"clean\") \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setStopWords(eng_stopwords)\n",
    "\n",
    "# lemmatizer = LemmatizerModel.pretrained() \\\n",
    "#     .setInputCols([\"clean\"]) \\\n",
    "#     .setOutputCol(\"lemma\")\n",
    "\n",
    "lemmatizer=LemmatizerModel.load('lemma_antbnc_en_2.0.2_2.4_1556480454569/')\\\n",
    "    .setInputCols([\"clean\"]) \\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "    .setInputCols([\"lemma\"]) \\\n",
    "    .setOutputCol(\"stem\")\n",
    "\n",
    "# word_embeddings=ElmoEmbeddings.pretrained()\\\n",
    "#     .setInputCols([\"document\", \"lemma\"])\\\n",
    "#     .setOutputCol(\"embedding\")\n",
    "\n",
    "# word_embeddings=ElmoEmbeddings.load('elmo_en_2.4.0_2.4_1580488815299/')\\\n",
    "#     .setInputCols([\"document\", \"lemma\"])\\\n",
    "#     .setOutputCol(\"embedding\")\n",
    "\n",
    "\n",
    "# sentence_embeddings=SentenceEmbeddings()\\\n",
    "#     .setInputCols([\"document\", \"embedding\"])\\\n",
    "#     .setOutputCol(\"sentence_embedding\")\\\n",
    "#     .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "\n",
    "ngrams_cum = NGramGenerator() \\\n",
    "    .setInputCols([\"stem\"]) \\\n",
    "    .setOutputCol(\"ngram\") \\\n",
    "    .setN(2) \\\n",
    "    .setEnableCumulative(True)\\\n",
    "    .setDelimiter(\"_\") # Default is space\n",
    "\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"ngram\"]) \\\n",
    "    .setOutputCols(['tokens'])\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "#     sentence_detector, \n",
    "    tokenizer, \n",
    "    normalizer, \n",
    "    stopwords_cleaner,\n",
    "    lemmatizer,\n",
    "    stemmer,\n",
    "#     word_embeddings,\n",
    "#     sentence_embeddings,\n",
    "    ngrams_cum,\n",
    "    finisher\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.select(\n",
    "        'status_id',\n",
    "        'created_at',\n",
    "        F.from_unixtime(F.unix_timestamp('created_at', 'yyyy-MM-dd')).cast('timestamp').alias('date'),\n",
    "        F.explode(\"tokens\").alias(\"word\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.groupBy(['word', 'date'])\\\n",
    "    .agg(F.countDistinct(\"status_id\").alias(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>date</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ufc</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>popular</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sport</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>entir</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>world</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6636</td>\n",
       "      <td>univers_amp</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6637</td>\n",
       "      <td>self</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6638</td>\n",
       "      <td>perhap</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6639</td>\n",
       "      <td>face_disciplin</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6640</td>\n",
       "      <td>bulk_order</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6641 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word       date  count\n",
       "0                ufc 2020-03-13      1\n",
       "1            popular 2020-03-13      1\n",
       "2              sport 2020-03-13     15\n",
       "3              entir 2020-03-13      1\n",
       "4              world 2020-03-13     17\n",
       "...              ...        ...    ...\n",
       "6636     univers_amp 2020-03-13      1\n",
       "6637            self 2020-03-13      2\n",
       "6638          perhap 2020-03-13      1\n",
       "6639  face_disciplin 2020-03-13      1\n",
       "6640      bulk_order 2020-03-13      1\n",
       "\n",
       "[6641 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result.toPandas()\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .option(\"parserLib\", \"univocity\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(\"word_count.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spark.read\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .option(\"parserLib\", \"univocity\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .parquet(\"word_count.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result.groupby('word')\\\n",
    "    .agg(F.sum('count').alias('count'))\\\n",
    "    .orderBy(F.desc('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [row[0] for row in result2.limit(1000).select('word').collect()]\n",
    "if 'date' in words:\n",
    "    words.remove('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = result.groupBy('date').pivot('word', words).max('count').orderBy('date').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>coronaviru</th>\n",
       "      <th>covid</th>\n",
       "      <th>coronaviruspandem</th>\n",
       "      <th>peopl</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>ne</th>\n",
       "      <th>time</th>\n",
       "      <th>spread</th>\n",
       "      <th>...</th>\n",
       "      <th>french</th>\n",
       "      <th>egg</th>\n",
       "      <th>pastri_chef</th>\n",
       "      <th>easteregg_coronaviru</th>\n",
       "      <th>ncaatourna</th>\n",
       "      <th>hour_thegameplan</th>\n",
       "      <th>nfl_ncaa</th>\n",
       "      <th>railwai</th>\n",
       "      <th>rise_coronaviru</th>\n",
       "      <th>effort_bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>239</td>\n",
       "      <td>143</td>\n",
       "      <td>77</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  coronaviru  covid  coronaviruspandem  peopl  get  go  ne  time  \\\n",
       "0 2020-03-13         239    143                 77     32   29  27  24    24   \n",
       "\n",
       "   spread  ...  french  egg  pastri_chef  easteregg_coronaviru  ncaatourna  \\\n",
       "0      23  ...       1    1            1                     1           1   \n",
       "\n",
       "   hour_thegameplan  nfl_ncaa  railwai  rise_coronaviru  effort_bid  \n",
       "0                 1         1        1                1           1  \n",
       "\n",
       "[1 rows x 1001 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases = spark.read.csv('covid_numconf.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = lambda i: i * 86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases = df_cases.select(\n",
    "        F.from_unixtime(F.unix_timestamp('date', 'yyyy-MM-dd')).cast('timestamp').alias('date'),\n",
    "        F.col('numconf').cast('Long'),\n",
    "        F.lit(1).alias('temp')\n",
    "    )\n",
    "\n",
    "window = Window.partitionBy('temp').orderBy('date')\n",
    "\n",
    "df_cases = df_cases.withColumn(\"numconf_lead3\", (F.lead('numconf', 3).over(window)))\n",
    "df_cases = df_cases.withColumn(\"numconf_lead7\", (F.lead('numconf', 7).over(window)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>numconf</th>\n",
       "      <th>temp</th>\n",
       "      <th>num_conf_lead3</th>\n",
       "      <th>num_conf_lead7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>90.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>138.0</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>176.0</td>\n",
       "      <td>424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>193.0</td>\n",
       "      <td>569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>249.0</td>\n",
       "      <td>846.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>324.0</td>\n",
       "      <td>971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>424.0</td>\n",
       "      <td>1302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>1430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>324</td>\n",
       "      <td>1</td>\n",
       "      <td>846.0</td>\n",
       "      <td>1646.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>424</td>\n",
       "      <td>1</td>\n",
       "      <td>971.0</td>\n",
       "      <td>1959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>569</td>\n",
       "      <td>1</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>3385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>846</td>\n",
       "      <td>1</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>4018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>971</td>\n",
       "      <td>1</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>4675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>1302</td>\n",
       "      <td>1</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>5386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>1430</td>\n",
       "      <td>1</td>\n",
       "      <td>3385.0</td>\n",
       "      <td>6255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>1646</td>\n",
       "      <td>1</td>\n",
       "      <td>4018.0</td>\n",
       "      <td>7424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>4675.0</td>\n",
       "      <td>8536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>3385</td>\n",
       "      <td>1</td>\n",
       "      <td>5386.0</td>\n",
       "      <td>9595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>4018</td>\n",
       "      <td>1</td>\n",
       "      <td>6255.0</td>\n",
       "      <td>11268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>4675</td>\n",
       "      <td>1</td>\n",
       "      <td>7424.0</td>\n",
       "      <td>12519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>5386</td>\n",
       "      <td>1</td>\n",
       "      <td>8536.0</td>\n",
       "      <td>13882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>6255</td>\n",
       "      <td>1</td>\n",
       "      <td>9595.0</td>\n",
       "      <td>15496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>7424</td>\n",
       "      <td>1</td>\n",
       "      <td>11268.0</td>\n",
       "      <td>16653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>8536</td>\n",
       "      <td>1</td>\n",
       "      <td>12519.0</td>\n",
       "      <td>17883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>9595</td>\n",
       "      <td>1</td>\n",
       "      <td>13882.0</td>\n",
       "      <td>19274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>11268</td>\n",
       "      <td>1</td>\n",
       "      <td>15496.0</td>\n",
       "      <td>20748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>12519</td>\n",
       "      <td>1</td>\n",
       "      <td>16653.0</td>\n",
       "      <td>22133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>13882</td>\n",
       "      <td>1</td>\n",
       "      <td>17883.0</td>\n",
       "      <td>23301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>15496</td>\n",
       "      <td>1</td>\n",
       "      <td>19274.0</td>\n",
       "      <td>24365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>16653</td>\n",
       "      <td>1</td>\n",
       "      <td>20748.0</td>\n",
       "      <td>25663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>17883</td>\n",
       "      <td>1</td>\n",
       "      <td>22133.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>19274</td>\n",
       "      <td>1</td>\n",
       "      <td>23301.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>20748</td>\n",
       "      <td>1</td>\n",
       "      <td>24365.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>22133</td>\n",
       "      <td>1</td>\n",
       "      <td>25663.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>23301</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>24365</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>25663</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  numconf  temp  num_conf_lead3  num_conf_lead7\n",
       "0  2020-03-01       24     1            39.0            62.0\n",
       "1  2020-03-02       28     1            45.0            77.0\n",
       "2  2020-03-03       33     1            51.0            90.0\n",
       "3  2020-03-04       39     1            57.0           103.0\n",
       "4  2020-03-05       45     1            62.0           138.0\n",
       "5  2020-03-06       51     1            77.0           176.0\n",
       "6  2020-03-07       57     1            90.0           193.0\n",
       "7  2020-03-08       62     1           103.0           249.0\n",
       "8  2020-03-09       77     1           138.0           324.0\n",
       "9  2020-03-10       90     1           176.0           424.0\n",
       "10 2020-03-11      103     1           193.0           569.0\n",
       "11 2020-03-12      138     1           249.0           846.0\n",
       "12 2020-03-13      176     1           324.0           971.0\n",
       "13 2020-03-14      193     1           424.0          1302.0\n",
       "14 2020-03-15      249     1           569.0          1430.0\n",
       "15 2020-03-16      324     1           846.0          1646.0\n",
       "16 2020-03-17      424     1           971.0          1959.0\n",
       "17 2020-03-18      569     1          1302.0          3385.0\n",
       "18 2020-03-19      846     1          1430.0          4018.0\n",
       "19 2020-03-20      971     1          1646.0          4675.0\n",
       "20 2020-03-21     1302     1          1959.0          5386.0\n",
       "21 2020-03-22     1430     1          3385.0          6255.0\n",
       "22 2020-03-23     1646     1          4018.0          7424.0\n",
       "23 2020-03-24     1959     1          4675.0          8536.0\n",
       "24 2020-03-25     3385     1          5386.0          9595.0\n",
       "25 2020-03-26     4018     1          6255.0         11268.0\n",
       "26 2020-03-27     4675     1          7424.0         12519.0\n",
       "27 2020-03-28     5386     1          8536.0         13882.0\n",
       "28 2020-03-29     6255     1          9595.0         15496.0\n",
       "29 2020-03-30     7424     1         11268.0         16653.0\n",
       "30 2020-03-31     8536     1         12519.0         17883.0\n",
       "31 2020-04-01     9595     1         13882.0         19274.0\n",
       "32 2020-04-02    11268     1         15496.0         20748.0\n",
       "33 2020-04-03    12519     1         16653.0         22133.0\n",
       "34 2020-04-04    13882     1         17883.0         23301.0\n",
       "35 2020-04-05    15496     1         19274.0         24365.0\n",
       "36 2020-04-06    16653     1         20748.0         25663.0\n",
       "37 2020-04-07    17883     1         22133.0             NaN\n",
       "38 2020-04-08    19274     1         23301.0             NaN\n",
       "39 2020-04-09    20748     1         24365.0             NaN\n",
       "40 2020-04-10    22133     1         25663.0             NaN\n",
       "41 2020-04-11    23301     1             NaN             NaN\n",
       "42 2020-04-12    24365     1             NaN             NaN\n",
       "43 2020-04-13    25663     1             NaN             NaN"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cases.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = result3.join(df_cases, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4.stat.corr(\"coronaviru\", \"numconf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4.write\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .option(\"parserLib\", \"univocity\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(\"word_count_pivot.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coefs_lead3 = [result4.stat.corr(w, 'numconf_lead3') for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-b9ce02cf9f1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorr_coefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'numconf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-151-b9ce02cf9f1b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorr_coefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'numconf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/pyspark/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcorr\u001b[0;34m(self, col1, col2, method)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m     \u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyspark/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcorr\u001b[0;34m(self, col1, col2, method)\u001b[0m\n\u001b[1;32m   1913\u001b[0m             raise ValueError(\"Currently only the calculation of the Pearson Correlation \" +\n\u001b[1;32m   1914\u001b[0m                              \"coefficient is supported.\")\n\u001b[0;32m-> 1915\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyspark/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyspark/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyspark/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyspark/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corr_coefs = [result4.stat.corr(w, 'numconf') for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(zip(words, corr_coefs))\n",
    "corr_rdd = rdd.map(lambda x: Row(word=x[0], corr=x[1]))\n",
    "corr_df = spark.createDataFrame(corr_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(\"word_correlation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
