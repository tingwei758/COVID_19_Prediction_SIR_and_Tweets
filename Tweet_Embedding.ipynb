{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from nltk.corpus import stopwords\n",
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf = SparkConf().set(\"spark.jars\", \"./spark-nlp_2.11-2.4.5.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder\\\n",
    "#     .appName('NLP model')\\\n",
    "#     .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.4.5\")\\\n",
    "#     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.2.13:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a1b31ae90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparknlp.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .option(\"parserLib\", \"univocity\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .csv(\"tweets\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1238253442063310848</td>\n",
       "      <td>532343475</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>The UFC is about to be the most popular sport ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1238253441778098177</td>\n",
       "      <td>165879150</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>The great toilet paper depression of 2020 #Toi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1238253440486313988</td>\n",
       "      <td>569242704</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>The 'Spotlight Show' with @janeyleegrace on @u...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1238253439051870208</td>\n",
       "      <td>16368021</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>Because we all the time in the world right? @s...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1238253440821649408</td>\n",
       "      <td>1057148786189824000</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>French pastry chef shows off Easter eggs model...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1238253442034020354</td>\n",
       "      <td>1093544067219292161</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>ICYMI - Hour 2 of #TheGamePlan with @DaveWNSP ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1238253441564266496</td>\n",
       "      <td>39743812</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>With rising #Coronavirus cases in India, which...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1238253441517928448</td>\n",
       "      <td>17852186</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>#ICYMI: #Ontario #MPPs may temporarily suspend...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1238253440603541504</td>\n",
       "      <td>1454687180</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>Despite having only 3 confirmed #coronavirus c...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1238253440461135873</td>\n",
       "      <td>19047089</td>\n",
       "      <td>2020-03-13T00:00:00Z</td>\n",
       "      <td>Autonomous #Robots Are Helping Kill #Coronavir...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id              user_id            created_at  \\\n",
       "0  1238253442063310848            532343475  2020-03-13T00:00:00Z   \n",
       "1  1238253441778098177            165879150  2020-03-13T00:00:00Z   \n",
       "2  1238253440486313988            569242704  2020-03-13T00:00:00Z   \n",
       "3  1238253439051870208             16368021  2020-03-13T00:00:00Z   \n",
       "4  1238253440821649408  1057148786189824000  2020-03-13T00:00:00Z   \n",
       "5  1238253442034020354  1093544067219292161  2020-03-13T00:00:00Z   \n",
       "6  1238253441564266496             39743812  2020-03-13T00:00:00Z   \n",
       "7  1238253441517928448             17852186  2020-03-13T00:00:00Z   \n",
       "8  1238253440603541504           1454687180  2020-03-13T00:00:00Z   \n",
       "9  1238253440461135873             19047089  2020-03-13T00:00:00Z   \n",
       "\n",
       "                                                text lang  \n",
       "0  The UFC is about to be the most popular sport ...   en  \n",
       "1  The great toilet paper depression of 2020 #Toi...   en  \n",
       "2  The 'Spotlight Show' with @janeyleegrace on @u...   en  \n",
       "3  Because we all the time in the world right? @s...   en  \n",
       "4  French pastry chef shows off Easter eggs model...   en  \n",
       "5  ICYMI - Hour 2 of #TheGamePlan with @DaveWNSP ...   en  \n",
       "6  With rising #Coronavirus cases in India, which...   en  \n",
       "7  #ICYMI: #Ontario #MPPs may temporarily suspend...   en  \n",
       "8  Despite having only 3 confirmed #coronavirus c...   en  \n",
       "9  Autonomous #Robots Are Helping Kill #Coronavir...   en  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "elmo download started this may take some time.\n",
      "Approximate size to download 334.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "# sentence_detector = SentenceDetector() \\\n",
    "#     .setInputCols([\"document\"]) \\\n",
    "#     .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normal\")\\\n",
    "    .setCleanupPatterns(['[^A-Za-z]', 'http.*'])\\\n",
    "    .setLowercase(True)\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"normal\"]) \\\n",
    "    .setOutputCol(\"clean\") \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setStopWords(eng_stopwords)\n",
    "\n",
    "# lemmatizer = LemmatizerModel.pretrained() \\\n",
    "#     .setInputCols([\"clean\"]) \\\n",
    "#     .setOutputCol(\"lemma\")\n",
    "\n",
    "lemmatizer=LemmatizerModel.load('lemma_antbnc_en_2.0.2_2.4_1556480454569/')\\\n",
    "    .setInputCols([\"clean\"]) \\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "# stemmer = Stemmer() \\\n",
    "#     .setInputCols([\"clean_lemma\"]) \\\n",
    "#     .setOutputCol(\"stem\")\n",
    "\n",
    "# word_embeddings=ElmoEmbeddings.pretrained()\\\n",
    "#     .setInputCols([\"document\", \"lemma\"])\\\n",
    "#     .setOutputCol(\"embedding\")\n",
    "\n",
    "word_embeddings=ElmoEmbeddings.load('elmo_en_2.4.0_2.4_1580488815299/')\\\n",
    "    .setInputCols([\"document\", \"lemma\"])\\\n",
    "    .setOutputCol(\"embedding\")\n",
    "\n",
    "\n",
    "sentence_embeddings=SentenceEmbeddings()\\\n",
    "    .setInputCols([\"document\", \"embedding\"])\\\n",
    "    .setOutputCol(\"sentence_embedding\")\\\n",
    "    .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "\n",
    "# finisher = Finisher() \\\n",
    "#     .setInputCols([\"sentence_embedding\"]) \\\n",
    "#     .setOutputCols(['finished'])\\\n",
    "#     .setIncludeMetadata(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "#     sentence_detector, \n",
    "    tokenizer, \n",
    "    normalizer, \n",
    "    stopwords_cleaner,\n",
    "    lemmatizer,\n",
    "    word_embeddings,\n",
    "    sentence_embeddings,\n",
    "#     finisher\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.select(\n",
    "        'status_id',\n",
    "        'created_at',\n",
    "        'text',\n",
    "        F.explode(\"sentence_embedding\").alias(\"sentence_embedding\")\n",
    "      )\\\n",
    "    .select(\n",
    "        'status_id',\n",
    "        'created_at',\n",
    "        F.from_unixtime(F.unix_timestamp('created_at', 'yyyy-MM-dd')).cast('timestamp').alias('date'),\n",
    "        'text',\n",
    "        F.col(\"sentence_embedding.embeddings\").alias('embedding')\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .option(\"parserLib\", \"univocity\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(\"embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_date = result.groupBy('date')\\\n",
    "    .agg(\n",
    "        F.array(*[F.avg(F.col(\"embedding\")[i]) for i in range(512)]).alias(\"embedding\"),\n",
    "        F.count('*').alias('number_of_tweets')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_date.write\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .option(\"parserLib\", \"univocity\")\\\n",
    "    .option(\"multiLine\", \"true\")\\\n",
    "    .option(\"escape\", \"\\\"\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .parquet(\"nlp_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
